#!/usr/bin/env python3
"""
æ¸…ç†è„šæœ¬ï¼šä»å†å²æ•°æ®ä¸­ç§»é™¤æ— æ•ˆçš„è®¢é˜…é“¾æ¥
ä¸»è¦æ¸…ç†ï¼š
1. è®ºå›é“¾æ¥ã€æ•™ç¨‹é¡µé¢
2. æ— æ•ˆ token çš„è®¢é˜…é“¾æ¥
3. GitHub éè®¢é˜…é¡µé¢
"""

import json
import os
import sys
from urllib.parse import urlparse, parse_qs
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main_extract_fast import _is_valid_token, _validate_subscription_url_params

def is_valid_subscription_url(url: str) -> bool:
    """æ£€æŸ¥ URL æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è®¢é˜…é“¾æ¥"""
    
    # é»‘åå•æ¨¡å¼
    BLACKLIST_PATTERNS = [
        "forums/topic/", "forum.php", "/thread-", "/viewtopic.php", 
        "/showthread.php", "/discussion/", "sockscap64.com/forums",
        "github.com/releases", "/issues/", "/pull/", "/wiki/", "/docs/",
        "youtube.com", "youtu.be", "bilibili.com", "telegram.me", "t.me/",
        "/download/", "/archive/", "/blob/", "/commit/", "/compare/",
        "blackmatrix7/ios_rule_script", "domain-filter/", "easylist",
        "easyprivacy", "easylistchina", "adrules", "adguard",
        "clashx-pro/distribution_groups", "sub-web.netlify.app",
        "loyalsoldier/clash-rules", "help.wwkejishe.top/free-shadowrocket"
    ]
    
    url_lower = url.lower()
    
    # æ£€æŸ¥é»‘åå•æ¨¡å¼
    for pattern in BLACKLIST_PATTERNS:
        if pattern in url_lower:
            print(f"[é»‘åå•å‰”é™¤] {url}")
            return False
    
    # æ£€æŸ¥ URL å‚æ•°ï¼ˆtoken/key éªŒè¯ï¼‰
    if not _validate_subscription_url_params(url):
        print(f"[æ— æ•ˆå‚æ•°å‰”é™¤] {url}")
        return False
    
    # ç™½åå•åç¼€ï¼ˆyaml/yml/txtï¼‰
    path = urlparse(url).path.lower()
    if path.endswith(('.yaml', '.yml', '.txt')):
        return True
    
    # åŒ…å«è®¢é˜…å…³é”®è¯
    subscription_keywords = [
        'subscribe', 'subscription', 'sub', 'clash', 'v2ray', 'ss', 
        'vless', 'vmess', 'trojan', 'hysteria', 'tuic', 'nodes', 
        'proxies', 'proxy'
    ]
    
    if any(keyword in url_lower for keyword in subscription_keywords):
        return True
    
    print(f"[æ— å…³é”®è¯å‰”é™¤] {url}")
    return False

def clean_history_file(filepath: str):
    """æ¸…ç†å†å²æ–‡ä»¶ä¸­çš„æ— æ•ˆé“¾æ¥"""
    
    if not os.path.exists(filepath):
        print(f"å†å²æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return
    
    print(f"æ­£åœ¨æ¸…ç†å†å²æ–‡ä»¶: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # å¤‡ä»½åŸå§‹æ•°æ®
    backup_path = filepath + '.backup'
    with open(backup_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"å·²å¤‡ä»½åŸå§‹æ•°æ®åˆ°: {backup_path}")
    
    original_seen_count = len(data.get('seen', []))
    original_links_count = len(data.get('links', []))
    
    # æ¸…ç† seen åˆ—è¡¨
    if 'seen' in data:
        valid_seen = [url for url in data['seen'] if is_valid_subscription_url(url)]
        data['seen'] = valid_seen
        print(f"seen: {original_seen_count} -> {len(valid_seen)} (-{original_seen_count - len(valid_seen)})")
    
    # æ¸…ç† links åˆ—è¡¨
    if 'links' in data:
        valid_links = [url for url in data['links'] if is_valid_subscription_url(url)]
        data['links'] = valid_links
        print(f"links: {original_links_count} -> {len(valid_links)} (-{original_links_count - len(valid_links)})")
    
    # æ¸…ç† resource_keys
    if 'resource_keys' in data:
        original_keys_count = len(data['resource_keys'])
        valid_keys = {url: meta for url, meta in data['resource_keys'].items() 
                     if is_valid_subscription_url(url)}
        data['resource_keys'] = valid_keys
        print(f"resource_keys: {original_keys_count} -> {len(valid_keys)} (-{original_keys_count - len(valid_keys)})")
    
    # æ¸…ç† fail è®°å½•
    if 'fail' in data:
        original_fail_count = len(data['fail'])
        valid_fail = {url: count for url, count in data['fail'].items() 
                     if is_valid_subscription_url(url)}
        data['fail'] = valid_fail
        print(f"fail: {original_fail_count} -> {len(valid_fail)} (-{original_fail_count - len(valid_fail)})")
    
    # ä¿å­˜æ¸…ç†åçš„æ•°æ®
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å†å²æ–‡ä»¶æ¸…ç†å®Œæˆ: {filepath}")

def main():
    """ä¸»å‡½æ•°"""
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    history_path = os.path.join(project_root, 'data', 'history.json')
    
    print("ğŸ”¥ å¼€å§‹æ¸…ç†æ— æ•ˆè®¢é˜…é“¾æ¥...")
    
    # æ¸…ç†å†å²æ–‡ä»¶
    clean_history_file(history_path)
    
    print("\nâœ… æ¸…ç†å®Œæˆï¼")
    print("ğŸ’¡ å»ºè®®è¿è¡Œ main_extract_fast.py é‡æ–°ç”Ÿæˆè¾“å‡ºæ–‡ä»¶")

if __name__ == "__main__":
    main()